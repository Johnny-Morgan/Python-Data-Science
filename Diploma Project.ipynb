{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www.taoiseach.gov.ie/eng/News/Taoiseach's_Speeches/New%20Year's%20Day%20Statement%20by%20An%20Taoiseach.html\")\n",
    "c = r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(c, \"html.parser\")\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = all.replace(\"\\xa0\",\"\")\n",
    "all = all.replace(\"\\r\\n\",\"\")\n",
    "all = all.replace(\"var mapOverlayUrl = ''\",\"\")\n",
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = all.find_all(\"div\", {\"dir\":\"ltr\"})[0].text\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speech1.txt\", \"w\") as out_file:\n",
    "    out_file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape links to speeches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = requests.get(\"https://www.taoiseach.gov.ie/eng/News/Taoiseach's_Speeches/\")\n",
    "c1 = r1.content\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(c1, \"html.parser\")\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "for a in all:\n",
    "    print(a.find(\"a\")[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2013 - 2019 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368 speeches in 2013-19\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Taoiseach's_Speeches/?pageNumber=\"\n",
    "speech_string_2013_19 = \"\"\n",
    "count = 1\n",
    "for page in range(1,38):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "        c = r.content\n",
    "        #print(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "        soup = BeautifulSoup(c, \"html.parser\")\n",
    "        all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "        all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "        \n",
    "#         with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2013-2019/2013-2019_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#             out_file.write(all)\n",
    "        count = count + 1\n",
    "        speech_string_2013_19 += all\n",
    "        \n",
    "#print(speech_string_2013_19)\n",
    "print(str(count - 1) + \" speeches in 2013-19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ireland', 3719), ('’', 3695), ('government', 1820), ('people', 1800), ('new', 1762), ('irish', 1530), ('work', 1260), ('eu', 1131), ('european', 1075), ('jobs', 1053), ('economic', 979), ('year', 940), ('–', 923), ('plan', 863), ('country', 820), ('years', 802), ('many', 787), ('one', 784), ('economy', 752), ('today', 740), ('future', 708), ('investment', 691), ('time', 690), ('world', 686), ('public', 684), ('first', 673), ('%', 649), ('minister', 647), ('want', 643), ('‘', 631), ('support', 623), ('uk', 618), ('need', 613), ('last', 610), ('make', 584), ('continue', 564), ('like', 561), ('recovery', 557), ('important', 545), ('taoiseach', 539), ('across', 536), ('national', 531), ('good', 527), ('international', 519), ('know', 517), ('part', 496), ('europe', 475), ('council', 473), ('development', 471), ('tax', 468), ('next', 466), ('services', 465), ('business', 463), ('state', 457), ('ensure', 455), ('trade', 455), ('see', 451), ('northern', 451), ('agreement', 443), ('must', 443), ('union', 441), ('growth', 440), ('made', 437), ('well', 433), ('working', 430), ('including', 425), ('sector', 418), ('strong', 411), ('best', 411), ('believe', 409), ('brexit', 406), (':', 400), ('way', 398), ('companies', 396), ('help', 394), ('great', 391), ('every', 387), ('better', 383), ('challenges', 383), ('opportunity', 381), ('peace', 378), ('action', 377), ('process', 377), ('place', 368), ('progress', 361), ('political', 360), ('take', 353), ('thank', 352), ('issues', 352), ('global', 351), ('dublin', 349), ('much', 348), ('enterprise', 348), ('together', 346), ('programme', 343), ('president', 340), ('two', 339), ('budget', 338), ('back', 328), ('course', 327)]\n",
      "3\n",
      "557\n"
     ]
    }
   ],
   "source": [
    "speech_string_2013_19 = speech_string_2013_19.lower()\n",
    "words_2013_19 = word_tokenize(speech_string_2013_19)\n",
    "#print(len(words_2013_19))\n",
    "\n",
    "words_2013_19 = [w for w in words_2013_19 if not w in stop_words]\n",
    "#print(str(len(words_2013_19)) + \" words after removing stopwords\")\n",
    "all_words_2013_19 = nltk.FreqDist(words_2013_19)\n",
    "\n",
    "print(all_words_2013_19.most_common(100))\n",
    "print(all_words_2013_19[\"tiger\"])\n",
    "print(all_words_2013_19[\"recovery\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2012 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 speeches in 2012\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/2012/Taoiseach's_Speeches_2012?pageNumber=\"\n",
    "speech_string_2012 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,6):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "        c = r.content\n",
    "        \n",
    "        soup = BeautifulSoup(c, \"html.parser\")\n",
    "        all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "        all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "        \n",
    "#         with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2012/2012_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#             out_file.write(all)\n",
    "        count = count + 1\n",
    "        speech_string_2012 += all\n",
    "        \n",
    "#print(speech_string_2012)\n",
    "print(str(count - 1) + \" speeches in 2012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69677\n",
      "33858 words after removing stopwords\n",
      "[('european', 241), ('people', 233), ('new', 208), ('economic', 204), ('growth', 177), ('work', 165), ('jobs', 161), ('year', 150), ('council', 138), ('country', 118), ('important', 115), ('last', 115), ('investment', 109), ('international', 107), ('’', 106), ('europe', 104), ('many', 104), ('public', 103), ('support', 101), ('economy', 99), ('today', 98), ('world', 98), ('business', 97), ('one', 96), ('programme', 91), ('need', 90), ('eu', 88), ('meeting', 86), ('first', 86), ('time', 84), ('services', 84), ('financial', 83), ('president', 82), ('recovery', 79), ('plan', 77), ('continue', 77), ('years', 75), ('future', 72), (':', 71), ('made', 71), ('market', 71), ('make', 70), ('member', 69), ('national', 69), ('union', 68), ('including', 67), ('well', 67), ('sector', 67), ('companies', 67), ('2012', 65), ('strong', 65), ('ensure', 65), ('development', 65), ('progress', 65), ('working', 65), ('crisis', 64), ('key', 64), ('job', 64), ('energy', 64), ('best', 63), ('treaty', 63), ('across', 63), ('creation', 61), ('part', 60), ('reform', 60), ('like', 59), ('china', 59), ('action', 58), ('want', 58), ('issues', 56), ('social', 56), ('minister', 56), ('taoiseach', 55), ('employment', 55), ('week', 54), ('states', 54), ('great', 54), ('know', 54), ('level', 54), ('industry', 54), ('way', 54), ('opportunity', 53), ('welcome', 52), ('take', 51), ('forward', 51), ('process', 51), ('together', 51), ('change', 51), ('potential', 51), ('place', 50), ('policy', 50), ('recent', 50), ('role', 50), ('back', 50), ('global', 50), ('budget', 49), ('stability', 49), ('clear', 49), ('see', 49), (\"'\", 48)]\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "speech_string_2012 = speech_string_2012.lower()\n",
    "words_2012 = word_tokenize(speech_string_2012)\n",
    "print(len(words_2012))\n",
    "\n",
    "words_2012 = [w for w in words_2012 if not w in stop_words]\n",
    "print(str(len(words_2012)) + \" words after removing stopwords\")\n",
    "all_words_2012 = nltk.FreqDist(words_2012)\n",
    "\n",
    "print(all_words_2012.most_common(100))\n",
    "print(all_words_2012[\"tiger\"])\n",
    "print(all_words_2012[\"brexit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2011 Speeches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 speeches in 2011\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/2011/Taoiseach's_Speeches_2011?pageNumber=\"\n",
    "speech_string_2011 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,5):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "        c = r.content\n",
    "        \n",
    "        soup = BeautifulSoup(c, \"html.parser\")\n",
    "        all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "        all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "        \n",
    "#         with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2011/2011_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#             out_file.write(all)\n",
    "        count = count + 1\n",
    "        speech_string_2011 += all\n",
    "        \n",
    "#print(speech_string_2011)\n",
    "print(str(count - 1) + \" speeches in 2011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63747\n",
      "30989 words after removing stopwords\n",
      "[('ireland', 339), ('...', 277), ('government', 241), ('people', 187), ('european', 185), ('new', 180), ('economic', 150), ('irish', 141), ('council', 133), ('work', 132), ('public', 111), ('country', 111), ('programme', 99), ('business', 99), ('meeting', 95), ('national', 95), ('need', 92), ('first', 86), ('economy', 82), ('many', 80), ('growth', 77), ('must', 76), ('jobs', 76), ('member', 74), ('state', 74), ('states', 73), ('support', 73), ('energy', 72), ('make', 72), ('area', 71), ('time', 71), ('house', 69), ('euro', 68), ('one', 68), ('services', 67), (\"'\", 67), ('made', 65), ('today', 65), ('measures', 64), ('president', 64), ('including', 63), ('international', 63), ('important', 63), ('part', 63), (':', 63), ('system', 63), ('take', 62), ('future', 62), ('ensure', 62), ('world', 62), ('last', 62), ('union', 61), ('years', 61), ('like', 58), ('financial', 56), ('working', 55), ('sector', 55), ('good', 54), ('taoiseach', 53), ('year', 53), ('know', 53), ('agreed', 53), ('..', 53), ('much', 52), ('week', 52), ('continue', 52), ('change', 52), ('within', 51), ('report', 51), ('policy', 50), ('great', 50), ('place', 50), ('forward', 49), ('banking', 49), ('way', 49), ('crisis', 47), ('across', 47), ('recent', 46), ('next', 45), ('best', 45), ('%', 45), ('situation', 44), ('progress', 44), ('committed', 44), ('want', 44), ('day', 44), ('service', 44), ('political', 44), ('2011', 43), ('agreement', 43), ('welcome', 43), ('possible', 43), ('already', 42), ('two', 42), ('commission', 42), ('minister', 42), ('life', 42), ('set', 41), ('confidence', 41), ('process', 41)]\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "speech_string_2011 = speech_string_2011.lower()\n",
    "words_2011 = word_tokenize(speech_string_2011)\n",
    "print(len(words_2011))\n",
    "\n",
    "words_2011 = [w for w in words_2011 if not w in stop_words]\n",
    "print(str(len(words_2011)) + \" words after removing stopwords\")\n",
    "all_words_2011 = nltk.FreqDist(words_2011)\n",
    "\n",
    "print(all_words_2011.most_common(100))\n",
    "print(all_words_2011[\"tiger\"])\n",
    "print(all_words_2011[\"unemployed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2010 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 speeches in 2010\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/2010/Taoiseach's_Speeches_2010?pageNumber=\"\n",
    "speech_string_2010 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,6):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "        c = r.content\n",
    "        \n",
    "        soup = BeautifulSoup(c, \"html.parser\")\n",
    "        all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "        all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "        \n",
    "#         with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2010/2010_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#             out_file.write(all)\n",
    "        count = count + 1\n",
    "        speech_string_2010 += all\n",
    "        \n",
    "#print(speech_string_2010)\n",
    "print(str(count - 1) + \" speeches in 2010\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64691\n",
      "32641 words after removing stopwords\n",
      "[('ireland', 358), ('new', 236), ('government', 195), ('people', 165), ('irish', 163), ('economic', 150), ('economy', 145), ('public', 117), ('innovation', 113), ('companies', 110), ('today', 109), ('investment', 107), ('important', 105), ('future', 98), ('’', 98), ('like', 97), ('many', 97), ('business', 97), ('services', 94), ('growth', 91), ('jobs', 91), ('year', 90), ('work', 89), ('years', 84), ('development', 82), ('sector', 82), ('research', 81), ('need', 80), ('international', 74), ('well', 74), ('europe', 73), ('country', 73), ('european', 72), ('support', 72), ('great', 71), ('national', 69), ('time', 69), ('part', 68), ('education', 67), ('made', 66), ('world', 66), ('enterprise', 65), ('one', 65), ('programme', 65), ('best', 64), ('%', 64), ('place', 63), ('last', 61), ('service', 61), ('global', 60), ('significant', 60), ('key', 60), ('strategy', 59), ('go', 59), ('taoiseach', 58), (':', 57), ('agus', 57), ('level', 56), ('confidence', 55), ('system', 55), ('ensure', 54), ('recovery', 54), ('centre', 54), ('capital', 53), ('banking', 53), ('–', 53), ('2010', 52), ('know', 52), ('must', 52), ('na', 51), ('two', 50), ('including', 50), ('believe', 50), ('make', 49), ('report', 49), ('local', 49), ('course', 49), ('good', 48), ('across', 48), ('opportunity', 48), ('help', 48), ('see', 48), ('industry', 47), ('way', 47), ('energy', 47), ('brian', 46), ('take', 46), ('tourism', 46), ('community', 46), ('first', 45), ('set', 45), ('success', 45), ('major', 45), ('challenges', 45), ('cowen', 44), ('past', 44), ('strong', 44), ('potential', 44), ('together', 44), ('area', 43)]\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "speech_string_2010 = speech_string_2010.lower()\n",
    "words_2010 = word_tokenize(speech_string_2010)\n",
    "print(len(words_2010))\n",
    "\n",
    "words_2010 = [w for w in words_2010 if not w in stop_words]\n",
    "print(str(len(words_2010)) + \" words after removing stopwords\")\n",
    "all_words_2010 = nltk.FreqDist(words_2010)\n",
    "\n",
    "print(all_words_2010.most_common(100))\n",
    "print(all_words_2010[\"tiger\"])\n",
    "print(all_words_2010[\"recession\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2009 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 speeches in 2009\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/2009/Taoiseach's_Speeches_2009?pageNumber=\"\n",
    "speech_string_2009 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,6):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "        c = r.content\n",
    "        \n",
    "        soup = BeautifulSoup(c, \"html.parser\")\n",
    "        all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "        all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "        \n",
    "#         with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2009/2009_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#             out_file.write(all)\n",
    "        count = count + 1\n",
    "        speech_string_2009 += all\n",
    "        \n",
    "#print(speech_string_2009)\n",
    "print(str(count - 1) + \" speeches in 2009\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64672\n",
      "32469 words after removing stopwords\n",
      "[('ireland', 326), ('new', 235), ('economic', 181), ('government', 178), ('economy', 169), ('irish', 168), ('people', 141), ('public', 134), ('business', 112), ('work', 111), ('many', 109), ('support', 103), ('years', 101), ('agus', 101), ('jobs', 99), ('future', 93), ('companies', 93), ('international', 88), ('services', 88), ('development', 87), ('investment', 86), ('must', 85), ('today', 83), ('’', 82), ('european', 80), ('global', 79), ('national', 77), ('one', 77), ('service', 75), ('innovation', 75), ('council', 75), ('na', 74), ('need', 73), ('year', 72), ('social', 71), ('great', 71), ('union', 71), ('world', 70), ('first', 68), ('time', 67), ('well', 66), ('report', 66), ('country', 65), ('enterprise', 65), ('make', 65), ('go', 65), ('smart', 64), ('want', 64), ('%', 63), ('research', 60), ('way', 59), ('state', 58), ('difficult', 57), ('provide', 57), ('tax', 57), ('help', 57), (':', 57), ('part', 57), ('growth', 57), ('sector', 57), ('know', 57), ('like', 56), ('children', 56), ('clear', 55), ('budget', 54), ('made', 54), ('crisis', 54), ('ar', 54), ('confidence', 52), ('continue', 52), ('ensure', 52), ('education', 52), ('last', 51), ('important', 51), ('key', 50), ('across', 50), ('including', 48), ('significant', 48), ('much', 48), ('seo', 48), ('take', 47), ('taoiseach', 46), ('2009', 46), ('recovery', 46), ('current', 46), ('level', 45), ('energy', 45), ('institutions', 45), ('financial', 44), ('forward', 44), ('employment', 44), ('next', 44), ('minister', 44), ('best', 44), ('challenges', 44), ('europe', 43), ('together', 43), ('recent', 42), ('high', 42), ('partnership', 42)]\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "speech_string_2009 = speech_string_2009.lower()\n",
    "words_2009 = word_tokenize(speech_string_2009)\n",
    "print(len(words_2009))\n",
    "\n",
    "words_2009 = [w for w in words_2009 if not w in stop_words]\n",
    "print(str(len(words_2009)) + \" words after removing stopwords\")\n",
    "all_words_2009 = nltk.FreqDist(words_2009)\n",
    "\n",
    "print(all_words_2009.most_common(100))\n",
    "print(all_words_2009[\"tiger\"])\n",
    "print(all_words_2009[\"unemployed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2008 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 speeches in 2008\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/2008/Taoiseach's_Speeches_2008?pageNumber=\"\n",
    "speech_string_2008 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,6):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "        c = r.content\n",
    "        \n",
    "        soup = BeautifulSoup(c, \"html.parser\")\n",
    "        all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "        all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "        \n",
    "#         with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2008/2008_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#             out_file.write(all)\n",
    "        count = count + 1\n",
    "        \n",
    "        speech_string_2008 += all\n",
    "        \n",
    "#print(speech_string_2008)\n",
    "print(str(count - 1) + \" speeches in 2008\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4798\n",
      "2414 words after removing stopwords\n",
      "[('public', 85), ('service', 76), ('oecd', 49), ('report', 26), ('’', 22), ('government', 19), ('change', 18), ('irish', 15), ('need', 15), ('ireland', 15), ('agencies', 15), ('development', 14), ('better', 14), ('system', 12), ('–', 12), ('reform', 12), ('greater', 11), ('performance', 11), ('programme', 10), ('e-government', 10), ('policy', 10), ('staff', 10), ('however', 9), ('services', 9), ('integrated', 9), ('level', 9), ('delivery', 9), ('across', 9), ('senior', 9), ('within', 9), ('management', 8), ('world', 8), ('many', 8), ('review', 8), ('economic', 8), ('citizens', 8), ('departments', 8), ('new', 8), ('first', 7), ('hunger', 7), ('challenges', 7), ('goals', 7), ('bodies', 7), ('food', 6), ('particularly', 6), ('already', 6), ('must', 6), ('analysis', 6), ('social', 6), ('clear', 6), ('increased', 6), ('example', 6), ('focus', 6), ('needs', 6), ('initiatives', 6), ('broader', 6), ('calls', 6), ('governance', 6), ('leadership', 6), ('improved', 6), ('global', 5), ('like', 5), ('people', 5), ('believe', 5), ('force', 5), ('%', 5), ('governments', 5), ('effective', 5), ('ensure', 5), ('impact', 5), ('much', 5), ('towards', 5), ('work', 5), ('part', 5), ('average', 5), ('success', 5), ('long', 5), ('terms', 5), ('levels', 5), (')', 5), ('given', 5), ('findings', 5), ('systems', 5), ('processes', 5), ('reforms', 5), ('needed', 5), ('offices', 5), ('organisations', 5), ('achieve', 5), ('develop', 5), ('significant', 5), ('different', 5), ('allow', 5), ('“', 5), ('”', 5), ('potential', 5), ('skills', 5), ('taoiseach', 4), ('issues', 4), ('security', 4)]\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "speech_string_2008 = speech_string_2008.lower()\n",
    "words_2008 = word_tokenize(speech_string_2008)\n",
    "print(len(words_2008))\n",
    "\n",
    "words_2008 = [w for w in words_2008 if not w in stop_words]\n",
    "print(str(len(words_2008)) + \" words after removing stopwords\")\n",
    "all_words_2008 = nltk.FreqDist(words_2008)\n",
    "\n",
    "print(all_words_2008.most_common(100))\n",
    "print(all_words_2008[\"tiger\"])\n",
    "print(all_words_2008[\"celtic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2007 & 2006 unavailable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2005 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 speeches in 2005\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/2005/Taoiseach's_Speeches_Archive_2005/?pageNumber=\"\n",
    "speech_string_2005 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,17):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "        c = r.content\n",
    "        \n",
    "        soup = BeautifulSoup(c, \"html.parser\")\n",
    "        all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "        all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "        \n",
    "#         with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2005/2005_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#             out_file.write(all)\n",
    "        count = count + 1\n",
    "        speech_string_2005 += all\n",
    "        \n",
    "#print(speech_string_2005)\n",
    "print(str(count - 1) + \" speeches in 2005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193603\n",
      "94017 words after removing stopwords\n",
      "[('’', 993), ('ireland', 734), ('people', 591), ('new', 542), ('–', 441), ('european', 439), ('government', 437), ('years', 432), ('development', 429), ('today', 429), ('many', 393), ('irish', 365), ('work', 356), ('eu', 323), ('important', 316), ('one', 307), ('social', 307), ('year', 304), ('national', 290), ('union', 285), ('europe', 276), ('know', 263), ('like', 257), ('time', 257), ('future', 254), ('dublin', 251), ('must', 249), ('support', 240), ('economic', 231), ('need', 228), ('success', 226), ('public', 210), ('great', 209), ('services', 201), ('recent', 200), ('community', 194), ('well', 194), ('world', 193), ('business', 191), ('council', 186), ('level', 185), ('delighted', 184), ('economy', 183), ('commitment', 177), ('society', 175), ('growth', 175), ('country', 173), ('see', 173), ('made', 172), ('good', 171), ('ensure', 171), ('last', 170), ('place', 170), ('states', 168), ('centre', 165), ('life', 163), ('particular', 161), ('partnership', 161), ('research', 158), ('continue', 157), ('much', 155), ('role', 155), ('programme', 154), ('service', 154), ('needs', 154), ('local', 154), ('million', 151), ('working', 150), ('%', 150), ('constitution', 150), ('part', 148), ('agreement', 148), ('city', 147), ('education', 147), ('international', 147), ('“', 144), ('however', 143), ('state', 143), ('member', 143), ('investment', 143), ('quality', 142), ('key', 142), ('best', 141), ('”', 140), ('area', 140), ('opportunity', 139), ('together', 139), ('first', 138), ('way', 138), ('particularly', 135), ('process', 134), ('sector', 134), ('forward', 133), ('health', 132), ('take', 130), ('past', 128), ('challenges', 128), ('progress', 128), ('clear', 128), ('children', 128)]\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "speech_string_2005 = speech_string_2005.lower()\n",
    "words_2005 = word_tokenize(speech_string_2005)\n",
    "print(len(words_2005))\n",
    "\n",
    "words_2005 = [w for w in words_2005 if not w in stop_words]\n",
    "print(str(len(words_2005)) + \" words after removing stopwords\")\n",
    "all_words_2005 = nltk.FreqDist(words_2005)\n",
    "\n",
    "print(all_words_2005.most_common(100))\n",
    "print(all_words_2005[\"tiger\"])\n",
    "print(all_words_2005[\"celtic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2004 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 speeches in 2004\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/2004/Taoiseach's_Speeches_Archive_2004/?pageNumber=\"\n",
    "speech_string_2004 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,4):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "        c = r.content\n",
    "        \n",
    "        soup = BeautifulSoup(c, \"html.parser\")\n",
    "        all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "        all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "        \n",
    "#         with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2004/2004_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#             out_file.write(all)\n",
    "        count = count + 1\n",
    "        \n",
    "        speech_string_2004 += all\n",
    "#print(speech_string_2004)\n",
    "print(str(count - 1) + \" speeches in 2004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63541\n",
      "30507 words after removing stopwords\n",
      "[('european', 350), ('union', 236), ('ireland', 217), ('new', 177), ('work', 163), ('presidency', 159), ('people', 150), ('social', 147), ('government', 146), ('irish', 146), ('agreement', 133), ('economic', 125), ('council', 125), ('eu', 104), ('europe', 102), ('years', 100), ('progress', 97), ('must', 97), ('time', 95), ('process', 88), ('last', 86), ('one', 85), ('year', 84), ('states', 84), ('growth', 80), ('services', 80), ('economy', 79), ('many', 79), ('forward', 79), ('member', 79), ('investment', 78), ('development', 78), ('today', 76), ('programme', 75), ('public', 75), ('good', 74), ('continue', 74), ('issues', 74), ('partnership', 73), ('support', 73), ('want', 73), ('employment', 72), ('future', 72), ('policy', 71), ('need', 70), ('agenda', 70), ('constitution', 69), ('important', 67), ('together', 67), ('%', 66), ('peace', 66), ('key', 66), ('national', 64), ('ensure', 64), ('make', 64), ('world', 64), ('role', 61), ('commitment', 61), ('working', 61), ('believe', 59), ('security', 58), ('better', 57), ('partners', 56), ('focus', 56), ('first', 56), ('well', 54), ('way', 54), ('political', 54), ('international', 53), ('northern', 53), ('strategy', 52), ('set', 52), ('president', 52), ('minister', 51), ('real', 51), ('made', 51), ('community', 51), ('report', 51), ('challenges', 51), ('level', 50), ('effective', 50), ('society', 50), ('success', 49), ('may', 49), ('unions', 49), ('opportunity', 49), ('recent', 48), ('however', 48), ('citizens', 48), ('take', 48), ('place', 47), ('know', 47), ('state', 46), ('parliament', 46), ('full', 45), ('clear', 45), ('possible', 44), ('period', 43), ('particular', 43), ('approach', 43)]\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "speech_string_2004 = speech_string_2004.lower()\n",
    "words_2004 = word_tokenize(speech_string_2004)\n",
    "print(len(words_2004))\n",
    "\n",
    "words_2004 = [w for w in words_2004 if not w in stop_words]\n",
    "print(str(len(words_2004)) + \" words after removing stopwords\")\n",
    "all_words_2004 = nltk.FreqDist(words_2004)\n",
    "\n",
    "print(all_words_2004.most_common(100))\n",
    "print(all_words_2004[\"tiger\"])\n",
    "print(all_words_2004[\"celtic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2003 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 speeches in 2003\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/2003/Taoiseach's_Speeches_Archive_2003/?pageNumber=\"\n",
    "speech_string_2003 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,5):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        try:\n",
    "            r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "            c = r.content\n",
    "\n",
    "            soup = BeautifulSoup(c, \"html.parser\")\n",
    "            all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "            all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "\n",
    "#             with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2003/2003_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#                 out_file.write(all)\n",
    "            count = count + 1\n",
    "            speech_string_2003 += all\n",
    "        except:\n",
    "            pass\n",
    "#print(speech_string_2003)\n",
    "print(str(count - 1) + \" speeches in 2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "77505\n",
      "36693 words after removing stopwords\n",
      "[('european', 306), ('union', 211), ('work', 186), ('people', 180), ('social', 179), ('economic', 171), ('council', 168), ('agreement', 154), ('development', 153), ('new', 146), ('years', 128), ('must', 119), ('progress', 118), ('many', 116), ('national', 116), ('world', 110), ('international', 109), ('eu', 106), ('public', 105), ('united', 103), ('europe', 103), ('last', 101), ('states', 100), ('countries', 100), ('time', 99), ('issues', 97), ('need', 96), ('security', 95), ('partnership', 94), ('process', 92), ('clear', 91), ('policy', 89), ('good', 88), ('important', 87), ('support', 85), ('%', 85), ('year', 83), ('made', 81), ('one', 81), ('together', 79), ('northern', 79), ('minister', 78), ('political', 78), ('part', 78), ('peace', 78), ('believe', 77), ('economy', 75), ('member', 74), ('governments', 74), ('full', 70), ('way', 70), ('trade', 69), ('particular', 68), ('want', 68), ('make', 68), ('well', 68), ('key', 67), ('investment', 66), ('ensure', 66), ('continue', 65), ('much', 64), ('two', 64), ('role', 63), ('recent', 63), ('change', 63), ('partners', 62), ('strong', 62), ('first', 62), ('report', 61), ('president', 60), ('country', 59), ('see', 58), ('presidency', 57), ('forward', 57), ('opportunity', 57), ('take', 57), ('nations', 57), ('real', 56), ('community', 56), ('number', 55), ('parties', 55), ('increase', 55), ('including', 54), ('treaty', 54), ('future', 54), ('great', 54), ('growth', 54), ('commitment', 54), ('society', 54), ('convention', 53), ('place', 53), ('increased', 53), ('issue', 52), ('agreed', 52), ('un', 52), ('committed', 52), ('global', 52), ('past', 51), (':', 51), ('state', 51)]\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "speech_string_2003 = speech_string_2003.lower()\n",
    "words_2003 = word_tokenize(speech_string_2003)\n",
    "print(len(words_2003))\n",
    "\n",
    "words_2003 = [w for w in words_2003 if not w in stop_words]\n",
    "print(str(len(words_2003)) + \" words after removing stopwords\")\n",
    "all_words_2003 = nltk.FreqDist(words_2003)\n",
    "\n",
    "print(all_words_2003.most_common(100))\n",
    "print(all_words_2003[\"tiger\"])\n",
    "print(all_words_2003[\"celtic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2002 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 speeches in 2002\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/2002/Taoiseach's_Speeches_Archive_2002/?pageNumber=\"\n",
    "speech_string_2002 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,9):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        try:\n",
    "            r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "            c = r.content\n",
    "\n",
    "            soup = BeautifulSoup(c, \"html.parser\")\n",
    "            all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "            all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "\n",
    "#             with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2002/2002_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#                 out_file.write(all)\n",
    "            count = count + 1\n",
    "            speech_string_2002 += all\n",
    "        except:\n",
    "            pass\n",
    "#print(speech_string_2002)\n",
    "print(str(count - 1) + \" speeches in 2002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93878\n",
      "43928 words after removing stopwords\n",
      "[('new', 364), ('people', 347), ('european', 338), ('social', 254), ('work', 253), ('europe', 228), ('development', 220), ('national', 204), ('union', 203), ('years', 187), ('economic', 174), ('future', 165), ('many', 158), ('great', 155), ('today', 142), ('important', 139), ('public', 133), ('one', 124), ('eu', 124), ('progress', 121), ('know', 120), ('well', 119), ('country', 118), ('believe', 117), ('support', 117), ('services', 116), ('time', 116), ('year', 116), ('commitment', 115), ('like', 113), ('success', 109), ('world', 108), ('council', 107), ('society', 106), ('made', 105), ('way', 102), ('economy', 100), ('last', 100), ('investment', 100), ('treaty', 100), ('opportunity', 99), ('must', 98), ('dublin', 97), ('policy', 97), ('make', 97), ('issues', 95), ('better', 93), ('nice', 93), ('community', 93), ('process', 92), ('strategy', 91), ('partnership', 91), ('good', 91), ('key', 91), ('see', 90), ('business', 88), ('need', 87), ('programme', 87), ('forward', 85), ('area', 85), ('ensure', 85), ('first', 85), ('education', 84), ('states', 82), ('take', 81), ('level', 81), ('member', 81), ('housing', 80), ('%', 80), ('life', 78), ('vital', 77), ('want', 76), ('peace', 75), ('project', 75), ('thank', 74), ('centre', 74), ('research', 73), ('working', 73), ('prosperity', 73), ('together', 72), ('building', 72), ('role', 72), ('much', 72), ('!', 72), ('plan', 71), ('poverty', 71), ('agreement', 70), ('information', 70), ('jobs', 69), ('wish', 69), ('service', 68), ('strong', 67), (':', 67), ('areas', 67), ('recent', 65), ('place', 65), ('look', 64), ('full', 64), ('every', 64), ('since', 64)]\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "speech_string_2002 = speech_string_2002.lower()\n",
    "words_2002 = word_tokenize(speech_string_2002)\n",
    "print(len(words_2002))\n",
    "\n",
    "words_2002 = [w for w in words_2002 if not w in stop_words]\n",
    "print(str(len(words_2002)) + \" words after removing stopwords\")\n",
    "all_words_2002 = nltk.FreqDist(words_2002)\n",
    "\n",
    "print(all_words_2002.most_common(100))\n",
    "print(all_words_2002[\"tiger\"])\n",
    "print(all_words_2002[\"celtic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2001 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 speeches in 2001\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/2001/Taoiseach's_Speeches_Archive_2001/?pageNumber=\"\n",
    "speech_string_2001 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,8):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        try:\n",
    "            r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "            c = r.content\n",
    "\n",
    "            soup = BeautifulSoup(c, \"html.parser\")\n",
    "            all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "            all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "\n",
    "#             with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2001/2001_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#                 out_file.write(all)\n",
    "            count = count + 1\n",
    "            \n",
    "            speech_string_2001 += all\n",
    "        except:\n",
    "            pass\n",
    "#print(speech_string_2001)\n",
    "print(str(count - 1) + \" speeches in 2001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_string_2001 = speech_string_2001.lower()\n",
    "words_2001 = word_tokenize(speech_string_2001)\n",
    "print(len(words_2001))\n",
    "\n",
    "words_2001 = [w for w in words_2001 if not w in stop_words]\n",
    "print(str(len(words_2001)) + \" words after removing stopwords\")\n",
    "all_words_2001 = nltk.FreqDist(words_2001)\n",
    "\n",
    "print(all_words_2001.most_common(100))\n",
    "print(all_words_2001[\"tiger\"])\n",
    "print(all_words_2001[\"celtic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2000 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 speeches in 2000\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/2000/Taoiseach's_Speeches_Archive_2000/?pageNumber=\"\n",
    "speech_string_2000 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,9):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        try:\n",
    "            r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "            c = r.content\n",
    "\n",
    "            soup = BeautifulSoup(c, \"html.parser\")\n",
    "            all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "            all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "\n",
    "#             with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/2000/2000_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#                 out_file.write(all)\n",
    "            count = count + 1\n",
    "            \n",
    "            speech_string_2000 += all\n",
    "        except:\n",
    "            pass\n",
    "#print(speech_string_2000)\n",
    "print(str(count - 1) + \" speeches in 2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107631\n",
      "52597 words after removing stopwords\n",
      "[('ireland', 508), ('new', 417), ('people', 367), ('development', 357), ('government', 308), ('social', 295), ('’', 268), ('irish', 262), ('economic', 224), ('work', 222), ('national', 210), ('years', 203), ('public', 176), ('programme', 173), ('partnership', 170), ('many', 159), ('today', 153), ('one', 149), ('time', 143), ('economy', 142), ('world', 141), ('service', 140), ('investment', 139), ('well', 139), ('great', 136), ('important', 136), ('business', 134), ('union', 134), ('process', 132), ('country', 124), ('like', 124), ('year', 123), ('believe', 122), ('made', 121), ('way', 121), ('agreement', 115), ('community', 115), ('services', 115), ('support', 112), ('first', 111), ('%', 111), ('key', 110), ('forward', 109), ('make', 109), ('european', 106), ('``', 105), ('last', 105), ('part', 102), ('future', 100), ('plan', 100)]\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "speech_string_2000 = speech_string_2000.lower()\n",
    "words_2000 = word_tokenize(speech_string_2000)\n",
    "print(len(words_2000))\n",
    "\n",
    "words_2000 = [w for w in words_2000 if not w in stop_words]\n",
    "print(str(len(words_2000)) + \" words after removing stopwords\")\n",
    "all_words_2000 = nltk.FreqDist(words_2000)\n",
    "\n",
    "print(all_words_2000.most_common(50))\n",
    "print(all_words_2000[\"tiger\"])\n",
    "print(all_words_2000[\"celtic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1999 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 speeches in 1999\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/1999/Taoiseach's_Speeches_Archive_1999/?pageNumber=\"\n",
    "speech_string_1999 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,9):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        try:\n",
    "            r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "            c = r.content\n",
    "\n",
    "            soup = BeautifulSoup(c, \"html.parser\")\n",
    "            all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "            all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "\n",
    "            # Write each speech to a file\n",
    "#             with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/1999/1999_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#                 out_file.write(all)\n",
    "            count = count + 1\n",
    "            \n",
    "            # create one sinlge string contain all speeches\n",
    "            speech_string_1999 += all\n",
    "        except:\n",
    "            pass\n",
    "#print(speech_string_1999)\n",
    "print(str(count - 1) + \" speeches in 1999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124026\n",
      "60213 words after removing stopwords\n",
      "[('ireland', 507), ('government', 456), ('irish', 397), ('new', 393), ('people', 390), ('social', 295), ('development', 287), ('agreement', 243), ('national', 241), ('partnership', 227), ('work', 226), ('public', 220), ('economic', 219), ('year', 183), ('years', 183), ('society', 179), ('many', 164), ('plan', 162), ('one', 159), ('way', 159), ('today', 157), ('important', 153), ('must', 153), ('’', 141), ('community', 140), ('time', 139), ('support', 139), ('good', 139), ('information', 136), ('``', 136), ('european', 136), ('taoiseach', 135), ('business', 134), ('service', 130), ('level', 127), ('minister', 127), ('last', 123), ('services', 122), ('made', 120), ('success', 119), (\"''\", 119), ('well', 117), ('%', 117), ('first', 117), ('country', 116), ('process', 115), ('local', 112), ('need', 111), ('make', 111), ('tax', 110)]\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "speech_string_1999 = speech_string_1999.lower()\n",
    "words_1999 = word_tokenize(speech_string_1999)\n",
    "print(len(words_1999))\n",
    "\n",
    "words_1999 = [w for w in words_1999 if not w in stop_words]\n",
    "print(str(len(words_1999)) + \" words after removing stopwords\")\n",
    "all_words_1999 = nltk.FreqDist(words_1999)\n",
    "\n",
    "print(all_words_1999.most_common(50))\n",
    "print(all_words_1999[\"tiger\"])\n",
    "print(all_words_2000[\"celtic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1998 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 1998 speeches\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/1998/Taoiseach's_Speeches_Archive_1998/?pageNumber=\"\n",
    "speech_string_1998 = \"\"\n",
    "\n",
    "count = 1\n",
    "for page in range(1,9):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    for a in all:\n",
    "        try:\n",
    "            r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "            c = r.content\n",
    "\n",
    "            soup = BeautifulSoup(c, \"html.parser\")\n",
    "            all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "            all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "\n",
    "            # Write each speech to a file\n",
    "#             with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/1998/1998_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#                 out_file.write(all)\n",
    "            count = count + 1\n",
    "            \n",
    "            # create one sinlge string contain all speeches\n",
    "            speech_string_1998 += all\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "#print(speech_string_1998) \n",
    "print(str(count - 1) + \" speeches in 1998\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119785\n",
      "56898\n",
      "[('ireland', 651), ('irish', 360), ('people', 355), ('government', 329), ('new', 270), ('economic', 254), ('agreement', 246), ('years', 203), ('many', 194), ('social', 192), ('public', 189), ('year', 187), ('development', 178), ('partnership', 174), ('european', 173), ('peace', 171), ('work', 166), ('good', 159), ('process', 159), ('support', 156), ('northern', 153), ('future', 153), ('one', 152), ('political', 151), ('time', 144), ('believe', 143), ('council', 142), ('made', 131), ('must', 131), ('important', 128), ('human', 124), ('last', 123), ('%', 123), ('first', 121), ('two', 121), ('rights', 121), ('union', 119), ('today', 119), ('business', 119), ('world', 119), ('like', 118), (':', 117), ('well', 117), ('national', 116), ('community', 116), ('need', 115), ('service', 113), ('issues', 107), ('level', 106), ('economy', 106)]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "speech_string_1998 = speech_string_1998.lower()\n",
    "words_1998 = word_tokenize(speech_string_1998)\n",
    "print(len(words_1998))\n",
    "\n",
    "words_1998 = [w for w in words_1998 if not w in stop_words]\n",
    "print(len(words_1998))\n",
    "all_words_1998 = nltk.FreqDist(words_1998)\n",
    "\n",
    "print(all_words_1998.most_common(50))\n",
    "\n",
    "# count occurences of a certain word\n",
    "print(all_words_1998[\"ceasefire\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1997 Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 speeches in 1997\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Archives/1997/Taoiseach's_Speeches_Archive_1997/?pageNumber=\"\n",
    "speech_string_1997 = \"\"\n",
    "count = 1\n",
    "\n",
    "for page in range(1,3):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"span\",{\"class\":\"ItemName\"})\n",
    "    \n",
    "    for a in all:\n",
    "        try:\n",
    "            r = requests.get(\"https://www.taoiseach.gov.ie\" + a.find(\"a\")[\"href\"])\n",
    "            c = r.content\n",
    "\n",
    "            soup = BeautifulSoup(c, \"html.parser\")\n",
    "            all = soup.find(\"div\", {\"class\":\"contentSub\"}).text\n",
    "            all = all.replace(\"var mapOverlayUrl = '';\",\"\")\n",
    "            \n",
    "            # Write each speech to a file\n",
    "#             with open(\"C:/Users/Johnny/Desktop/Data Science/Project/speeches/1997/1997_speech_\" + str(count) + \".txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "#                 out_file.write(all)\n",
    "            count = count + 1\n",
    "            \n",
    "            # create one sinlge string contain all speeches\n",
    "            speech_string_1997 += all \n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "#print(speech_string_1997)  \n",
    "print(str(count - 1) + \" speeches in 1997\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)\n",
    "speech_string_1997 = speech_string_1997.lower()\n",
    "words_1997 = word_tokenize(speech_string_1997)\n",
    "print(len(words_1997))\n",
    "\n",
    "words_1997 = [w for w in words_1997 if not w in stop_words]\n",
    "all_words_1997 = nltk.FreqDist(words_1997)\n",
    "print(len(words_1997))\n",
    "\n",
    "print(all_words_1997.most_common(10))\n",
    "\n",
    "# count occurences of a certain word\n",
    "all_words_1997[\"ceasefire\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.taoiseach.gov.ie/eng/News/Taoiseach's_Speeches/?pageNumber=\"\n",
    "count = 1\n",
    "for page in range(1,38):\n",
    "    r = requests.get(base_url + str(page))\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    dates = soup.find_all(\"span\",{\"class\":\"newsDate\"})\n",
    "    years = soup.find_all(\"span\",{\"class\":\"newsYear\"})\n",
    "    for date, year in zip(dates, years):\n",
    "        date = re.split('(\\d+)', date.text)\n",
    "        date = date[1] + \" \" + date[2] + \" \" + year.text\n",
    "        print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append(\".\")\n",
    "stop_words.append(\",\")\n",
    "stop_words.append(\"-\")\n",
    "stop_words.append(\";\")\n",
    "stop_words.append(\"us\")\n",
    "stop_words.append(\"'s\")\n",
    "stop_words.append(\"also\")\n",
    "stop_words.append(\"would\")\n",
    "stop_words.append(\"1997\")\n",
    "stop_words.append(\"1998\")\n",
    "stop_words.append(\"ireland\")\n",
    "stop_words.append(\"irish\")\n",
    "stop_words.append(\"government\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"fca94e9e-420b-460f-8611-6a5e88085df2\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"fca94e9e-420b-460f-8611-6a5e88085df2\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"fca94e9e-420b-460f-8611-6a5e88085df2\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'fca94e9e-420b-460f-8611-6a5e88085df2' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"fca94e9e-420b-460f-8611-6a5e88085df2\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"fca94e9e-420b-460f-8611-6a5e88085df2\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"fca94e9e-420b-460f-8611-6a5e88085df2\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'fca94e9e-420b-460f-8611-6a5e88085df2' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"fca94e9e-420b-460f-8611-6a5e88085df2\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"5b24bf65-c5c0-4b8e-9285-55c0f96140ae\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"1682899a-4f59-4680-83ae-7ff1bf51720e\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"abde2d21-3fc1-4e8d-acac-5056b3054ac5\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null},\"id\":\"d413227d-d991-41e6-a7ff-3e5aecdc65e8\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"e1bc1df6-09a6-42d5-a2af-a8970d8060f9\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"f452912b-5770-400d-a426-ba3b99b2ee2a\",\"type\":\"LinearScale\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"ba43a4f7-5d57-4992-9101-33624609b7b8\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"ac53e204-dbe4-4286-a9e4-00198107f976\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"formatter\":{\"id\":\"a0f9b990-0a08-4fe3-b3c5-5cb71988fa4b\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"11141786-b806-4091-8ef5-eae1a5fb0fda\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"2bed46a3-182c-4543-bbdb-b0aed8798960\",\"type\":\"BasicTicker\"}},\"id\":\"423fa822-b3bc-4fcc-82a1-dcd5a2983aa6\",\"type\":\"LinearAxis\"},{\"attributes\":{\"overlay\":{\"id\":\"c0c526e1-606e-4e75-b7f9-266c378cb770\",\"type\":\"BoxAnnotation\"}},\"id\":\"308e7d62-db25-4972-8c8f-9f799ace8c96\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"2bed46a3-182c-4543-bbdb-b0aed8798960\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"03e7f961-548e-4623-a597-fb7a07b265dd\",\"type\":\"SaveTool\"},{\"attributes\":{\"plot\":{\"id\":\"11141786-b806-4091-8ef5-eae1a5fb0fda\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"2bed46a3-182c-4543-bbdb-b0aed8798960\",\"type\":\"BasicTicker\"}},\"id\":\"4298640f-78b5-4b5d-a417-78ab3676d81e\",\"type\":\"Grid\"},{\"attributes\":{\"below\":[{\"id\":\"423fa822-b3bc-4fcc-82a1-dcd5a2983aa6\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"0b4ae355-16c8-4c18-921c-e161b59dd1f0\",\"type\":\"LinearAxis\"}],\"outline_line_alpha\":{\"value\":0.6},\"outline_line_color\":{\"value\":\"red\"},\"outline_line_width\":{\"value\":2},\"plot_height\":400,\"plot_width\":400,\"renderers\":[{\"id\":\"423fa822-b3bc-4fcc-82a1-dcd5a2983aa6\",\"type\":\"LinearAxis\"},{\"id\":\"4298640f-78b5-4b5d-a417-78ab3676d81e\",\"type\":\"Grid\"},{\"id\":\"0b4ae355-16c8-4c18-921c-e161b59dd1f0\",\"type\":\"LinearAxis\"},{\"id\":\"d0e1e6af-19e6-4235-abb1-6e5c661644fa\",\"type\":\"Grid\"},{\"id\":\"c0c526e1-606e-4e75-b7f9-266c378cb770\",\"type\":\"BoxAnnotation\"}],\"title\":{\"id\":\"ba43a4f7-5d57-4992-9101-33624609b7b8\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"2cdf0d13-cfed-48c1-975f-3d9f8f0f6609\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"d413227d-d991-41e6-a7ff-3e5aecdc65e8\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"48b7fab8-3e90-46ba-ac50-ba61c5de34f1\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"e21bca88-cba1-472d-a02c-b38befa06749\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"f452912b-5770-400d-a426-ba3b99b2ee2a\",\"type\":\"LinearScale\"}},\"id\":\"11141786-b806-4091-8ef5-eae1a5fb0fda\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"ced9c785-36f4-4b00-8597-9cc91a101740\",\"type\":\"ResetTool\"},{\"attributes\":{\"formatter\":{\"id\":\"abde2d21-3fc1-4e8d-acac-5056b3054ac5\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"11141786-b806-4091-8ef5-eae1a5fb0fda\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"af46dd00-ec79-4d7d-8c98-efe387490215\",\"type\":\"BasicTicker\"}},\"id\":\"0b4ae355-16c8-4c18-921c-e161b59dd1f0\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1034ffb8-152e-4704-9833-9db71dd376a2\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"af46dd00-ec79-4d7d-8c98-efe387490215\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null},\"id\":\"e21bca88-cba1-472d-a02c-b38befa06749\",\"type\":\"DataRange1d\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"c0c526e1-606e-4e75-b7f9-266c378cb770\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"11141786-b806-4091-8ef5-eae1a5fb0fda\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"af46dd00-ec79-4d7d-8c98-efe387490215\",\"type\":\"BasicTicker\"}},\"id\":\"d0e1e6af-19e6-4235-abb1-6e5c661644fa\",\"type\":\"Grid\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"e1bc1df6-09a6-42d5-a2af-a8970d8060f9\",\"type\":\"PanTool\"},{\"id\":\"ac53e204-dbe4-4286-a9e4-00198107f976\",\"type\":\"WheelZoomTool\"},{\"id\":\"308e7d62-db25-4972-8c8f-9f799ace8c96\",\"type\":\"BoxZoomTool\"},{\"id\":\"03e7f961-548e-4623-a597-fb7a07b265dd\",\"type\":\"SaveTool\"},{\"id\":\"ced9c785-36f4-4b00-8597-9cc91a101740\",\"type\":\"ResetTool\"},{\"id\":\"1034ffb8-152e-4704-9833-9db71dd376a2\",\"type\":\"HelpTool\"}]},\"id\":\"2cdf0d13-cfed-48c1-975f-3d9f8f0f6609\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"48b7fab8-3e90-46ba-ac50-ba61c5de34f1\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"a0f9b990-0a08-4fe3-b3c5-5cb71988fa4b\",\"type\":\"BasicTickFormatter\"}],\"root_ids\":[\"11141786-b806-4091-8ef5-eae1a5fb0fda\"]},\"title\":\"Bokeh Application\",\"version\":\"0.13.0\"}};\n",
       "  var render_items = [{\"docid\":\"1682899a-4f59-4680-83ae-7ff1bf51720e\",\"roots\":{\"11141786-b806-4091-8ef5-eae1a5fb0fda\":\"5b24bf65-c5c0-4b8e-9285-55c0f96140ae\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "11141786-b806-4091-8ef5-eae1a5fb0fda"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "\n",
    "output_notebook()\n",
    "year = [1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013]\n",
    "weight = [11, 74, 86, 85 ,96]\n",
    "\n",
    "p = figure(plot_width = 400, plot_height = 400)\n",
    "p.outline_line_width = 2\n",
    "p.outline_line_color = \"red\"\n",
    "p.outline_line_alpha = .6\n",
    "#p.outline_line_dash = [10,5]\n",
    "#p.circle(height, weight, size = 10, color = (11, 11, 11), alpha = 0.5)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
